<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Our Project Statement - LIS 500 Code and Power</title>
    <link rel="stylesheet" href="stylepage.css">
</head>
<body>
    <header>
        <a href="index.html"><img src="Frame 1.svg" width="75" height="75"></a>
        <h1>Our Reflection</h1>

        <!--adding icons to header-->
        <div class="header-icons">
            <a href="about.html"><img src="our project statement icon.svg" width="75" height="75"></a>
            <a href="resources.html"><img src="teachable machine icon.svg" width="75" height="75"></a>
        </div>

    </header>

    <!--navigation sidebar-->
    <div class="content-wrapper">
        <nav>
            <ul>
                <li><a href="index.html" class="hello">Home</a></li>
                <li><a href="#reflection">Our Project Statement</a></li>
                <li><a href="#Amar">Amar</a></li>
                <li><a href="#Shayla">Shayla</a></li>
            </ul>
        </nav>

        <main>
             <!--Our Reflection-->
             <section id="reflection">
                <h2>Our Project Statement</h2>
                <p>In the rapidly evolving field of artificial intelligence (AI) and machine learning (ML), tools like <a href="https://teachablemachine.withgoogle.com/">Google’s Teachable Machines</a> have democratized AI development, enabling users without technical expertise to creatively engage with this transformative technology. Our project—a Rock, Paper, Scissors game using this platform—demonstrates how AI can recognize and interpret human gestures in real time. This functionality relies on machine learning, which identifies patterns in data to make accurate predictions. Unlike traditional programming, which requires explicit coding of every rule, machine learning allows systems to learn from examples, making them adaptable and scalable for real-world applications. Beyond technical achievements, this project serves as a case study in exploring AI’s broader implications, including its educational potential, accessibility, and ethical challenges.</p>

                <p>However, while machine learning offers transformative possibilities, it introduces significant challenges, particularly regarding fairness and inclusivity. As <a href="https://iview.abc.net.au/show/ai-vs-human-the-creativity-experiment">AI vs. Human: The Creativity Experiment</a> highlights, AI often replicates existing patterns rather than producing unique solutions, raising questions about originality and systemic bias. These concerns are especially pertinent in educational and interactive tools designed for diverse users, where unfair or incomplete training data can exacerbate inequities. Our project addresses these issues by striving for inclusivity and transparency, showcasing responsible AI design in an engaging and accessible format. We aimed to obtain and utilize images in a fair manner. Utilizing ourselves and generated images, maintaing a form of ethics in our data.</p>

                <p>Using Google’s Teachable Machines, we embarked on the process of collecting datasets of hand gestures. Our approach emphasized diversity—incorporating variations in skin tones, hand shapes, and environmental conditions—to address potential biases. For instance, we experimented with different lighting settings and included samples featuring various accessories, such as rings, to ensure the model would perform accurately across diverse user contexts. The training phase involved several iterations, as we refined the dataset to balance representation and improve accuracy. The integration process was equally meticulous; we tested the AI’s responsiveness in real-time scenarios to ensure that the interface was intuitive and engaging. This iterative approach not only enhanced the technical robustness of the project but also provided invaluable insights into the challenges of creating inclusive AI systems. This approach underscores the importance of diverse and representative training data. Lessons from Joy Buolamwini’s Unmasking AI were instrumental in shaping this direction. For instance, Buolamwini’s concept of the “coded gaze” illustrates how AI can propagate the biases of its creators, underscoring the need for diverse datasets. For instance, facial recognition systems trained on non-representative datasets have been shown to perform poorly on darker skin tones, leading to critical failures in security and justice applications. As Buolamwini highlights, "When systems fail to detect faces with darker skin tones or classify them incorrectly, the consequences extend beyond mere inconvenience, embedding inequities into the very systems designed to serve us" (Buolamwini, p. 18). This highlights why our dataset for hand gestures prioritized diversity, with attention to variations in skin tones and environmental conditions, ensuring that our model could perform across a range of user inputs.</p>
                  
                <p>These lessons from Buolamwini also resonate in the design of our Rock, Paper, Scissors game, where we explore the tension between human and machine predictability. As <a href="/resources.html#rps">Daniel C. Dennett</a> points out, the best strategy in this game is to be unpredictable—something humans naturally struggle with due to inherent biases and patterns. In contrast, machines, while trained to follow specific rules, exhibit their own form of unpredictability, especially when their training data is limited. For example, our AI might occasionally misinterpret a "paper" gesture as "rock," a reminder that even machines are not immune to errors. This dynamic highlights a fascinating irony: humans strive to be unpredictable, mimicking the randomness of an untrained machine, while expecting machines to deliver flawless predictability. Our game invites users to explore this interplay, reflecting on the ways both humans and AI navigate the challenge of randomness and reliability. Through this playful interaction, we aim to provoke thought about the broader implications of training machines to replicate human behavior - especially regarding Buolamwini's discussion emphasizing that AI must be scrutinized for its ability to reproduce harmful societal norms rather than neutral reflections of human behavior​ (p. 246).</p>

                <p>The book also stresses the need for transparency and ethical accountability. As Buolamwini argues, AI systems must communicate their limitations and biases to users (p. 245). Acknowledging that no system is entirely unbiased, we have embraced transparency, openly discussing our model’s constraints and striving to improve continuously. We provided users with detailed explanations of the training process, potential biases in the dataset, and the limitations of the AI’s predictions. If you are interested in viewing our training data, <a href="https://github.com/sjcoombsnovii/sjcoombsnovii.github.io/tree/main/Images">click here</a>. This accountability builds trust and encourages critical engagement, promoting a more nuanced understanding of AI’s capabilities and challenges.</p>
                    
                <p>Moreover, Buolamwini’s vision of algorithmic justice has informed our project’s philosophy. By critically examining fairness and inclusivity, we sought to avoid perpetuating harmful biases and foster discussions about AI’s societal implications. Similarly, <a href="/Ellen Pao - 2020 - Tech, heal thyself  (2).pdf">Ellen Pao</a>’s critique of the tech industry highlights how the failure to prioritize inclusivity exacerbates disparities—a challenge our project seeks to address by centering marginalized perspectives. To further our machine's fairness, we conducted iterative testing to identify and mitigate potential biases in our model. During this process, we evaluated how the AI responded to edge cases—such as unusual angles—and adjusted the training data to improve robustness and inclusivity. Additionally, we incorporated transparency into the user experience by providing detailed documentation on the training process and limitations of our model. This not only informed users about the system’s constraints but also encouraged critical engagement with its outputs.</p>

                <p>This project not only demonstrates AI’s technical potential but also stimulates meaningful discussions about its ethical dimensions. By encouraging reflection on AI’s societal impacts, we hope this project sparks more conversations about the broader responsibilities of AI developers, educators, and policymakers. Future iterations could expand on these themes by exploring additional scenarios where AI intersects with fairness and accessibility.</p>
                    
            </section>
            <!--Broke it up horizontally with css to help it look cleaner-->
            <main class="about-main">
            <!--Amar About Me Section-->
            <section id="Amar" class="team-member">
                <img src="amarr.png" alt="Amar-image" class="team-member-image">
                <div class="team-member-info">
                    <h2>Amar Algogandi</h2>
                    <p class="team-member-title">UX Designer & Researcher</p>
                    <p class="team-member-bio">I’m Amar Algogandi, a UX designer and researcher dedicated to creating user-centered experiences that are intuitive and functional. My focus is on understanding user needs and applying that knowledge to design digital solutions that not only work well but also enhance the user experience. With my background in graphic design, I blend aesthetics with functionality to ensure that every interface is visually appealing and user-friendly. I enjoy the process of bringing creativity and practical solutions together to solve real-world problems through design.</p>
                </div>
            </section>
            

            <!--Shayla About Me Section-->
            <section id="Shayla" class="team-member">
                <img src="Shayla Headshot.jpg" class="team-member-image">
                <div class="team-member-info">
                    <h2>Shayla Coombs</h2>
                    <p class="team-member-title">MSI Student at UW-Madison, Client Experience Manager at Novii CPA, CEO & Co-Founder of OptiiFlo</p>
                    <p class="team-member-bio">I enjoy creating and reconstructing websites or platforms to achieve a more appealing feel, utilizing my knowledge in CX & UX I find myself pondering the user journey a lot as I build. When I am not behind my computer, you can find me mountain biking, trail running, or walking my dog, Arrow. Thanks for coming by!</p>
                </div>
            </section>
        </main class="about-main">

           

        </main>
    </div>
    <footer>
        <p>LIS 500 Amar Algogandi & Shayla Coombs</p>
    </footer>
</body>
</html>